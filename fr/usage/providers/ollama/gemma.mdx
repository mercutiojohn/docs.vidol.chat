---
title: Utiliser le mod√®le Google Gemma
description: Utilisez facilement le mod√®le Google Gemma pour des t√¢ches de traitement du langage naturel gr√¢ce √† l‚Äôint√©gration de LobeVidol avec Ollama. Installez Ollama, tirez le mod√®le Gemma, s√©lectionnez le mod√®le Gemma dans le panneau des mod√®les et commencez la conversation.
---

# Utiliser le mod√®le Google Gemma

<img
src="https://oss.vidol.chat/docs/2024/12/56d06a68955858385bd51dc590eb5156.png"
alt="Utiliser Gemma dans LobeVidol"
className="rounded-lg"
/>

[Gemma](https://blog.google/technology/developers/gemma-open-models/) est un grand mod√®le de langage (LLM) open source d√©velopp√© par Google, con√ßu pour fournir un mod√®le plus g√©n√©ral et flexible pour diverses t√¢ches de traitement du langage naturel. Maintenant, gr√¢ce √† l‚Äôint√©gration de LobeVidol avec [Ollama](https://ollama.com/), vous pouvez facilement utiliser Google Gemma dans LobeVidol.

## Introduction au mod√®le

Gemma est une s√©rie de grands mod√®les de langage open source lanc√©e par Google, comprenant des tailles de 2B et 7B. Ces mod√®les pr√©sentent les caract√©ristiques suivantes :

- Construit sur la technologie Gemini
- Prend en charge des capacit√©s de traitement multilingue
- Test√© rigoureusement pour la s√©curit√©
- Adapt√© √† divers types de t√¢ches de traitement du langage naturel

## Guide d'utilisation

Ce document vous guidera sur la fa√ßon d'utiliser Google Gemma dans LobeVidol :

### √âtape 1 : Installer Ollama localement

Tout d'abord, vous devez installer Ollama. Pour le processus d'installation, veuillez consulter la [documentation d'utilisation d'Ollama](/fr/docs/usage/providers/ollama).

### √âtape 2 : Tirer le mod√®le Google Gemma localement avec Ollama

Une fois Ollama install√©, vous pouvez installer le mod√®le Google Gemma avec la commande suivante :

```bash
# Installer le mod√®le 7B
ollama pull gemma

# Ou installer le mod√®le 2B
ollama pull gemma:2b
```

<img
src="https://oss.vidol.chat/assets/a913a0827535d10e79a2f2c2593d6ac2.webp"
alt="Tirer le mod√®le Gemma avec Ollama"
className="rounded-lg"
/>

### √âtape 3 : S√©lectionner le mod√®le Gemma

Dans la page de session, ouvrez le panneau des mod√®les, puis s√©lectionnez le mod√®le Gemma.

<img
src="https://oss.vidol.chat/assets/78deb22856ec7b50ae7cc782c743598f.webp"
alt="S√©lectionner le mod√®le Gemma dans le panneau de s√©lection des mod√®les"
className="rounded-lg"
/>

<Note>
  Si vous ne voyez pas le fournisseur Ollama dans le panneau de s√©lection des mod√®les, veuillez consulter [Int√©gration avec Ollama](/fr/docs/self-hosting/examples/ollama) pour savoir comment activer le fournisseur Ollama dans LobeVidol.
</Note>

## Configuration avanc√©e

Vous pouvez optimiser les performances de Gemma en modifiant les param√®tres du mod√®le :

| Nom du param√®tre | Description                | Valeur recommand√©e |
| ---------------- | -------------------------- | ------------------ |
| temperature      | Contr√¥le la randomisation de la sortie | 0.7                |
| top\_p           | Contr√¥le la diversit√© de la sortie      | 0.9                |
| max\_tokens      | Longueur maximale de la r√©ponse         | 4096               |

## Cas d'utilisation

Le mod√®le Gemma est adapt√© √† divers sc√©narios :

- üí¨ Conversations quotidiennes et questions-r√©ponses
- üìù G√©n√©ration et cr√©ation de texte
- üîç Extraction et r√©sum√© d'informations
- üéØ Questions-r√©ponses sur des connaissances sp√©cifiques

## Questions fr√©quentes

<Accordion title="Combien d'espace de stockage le mod√®le Gemma occupe-t-il ?">
  - Le mod√®le Gemma 7B occupe environ 4 Go d'espace de stockage
  - Le mod√®le Gemma 2B occupe environ 1,5 Go d'espace de stockage
</Accordion>

<Accordion title="Comment am√©liorer la vitesse de r√©ponse du mod√®le ?">
  - Utiliser un GPU plus r√©cent peut consid√©rablement am√©liorer la vitesse d'inf√©rence
  - R√©duire l√©g√®rement le param√®tre max_tokens
  - Choisir une version de mod√®le plus petite (comme 2B)
</Accordion>

## Ressources connexes

- [Documentation officielle de Gemma](https://blog.google/technology/developers/gemma-open-models/)
- [Site officiel d'Ollama](https://ollama.com/)
- [Centre de documentation de LobeVidol](/fr/docs)

